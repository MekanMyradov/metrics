{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "748e010d",
   "metadata": {},
   "source": [
    "# Mean Euc Distance to all same type cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c3d43e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_date = \"2025-07-11\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fcbeb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import scib\n",
    "import math\n",
    "import warnings\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "plt.style.use(\"../nature.mplstyle\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import cdist, jensenshannon\n",
    "from scipy.special import kl_div\n",
    "from scipy.stats import wasserstein_distance\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe499257",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7853726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../results/2025-07-11/out'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dir = f\"../results/{folder_date}/out\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "results_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8e9fb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the parent directory to sys.path\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "from graph_connectivity_per_celltype import graph_connectivity_per_celltype\n",
    "from isolated_labels import isolated_labels_asw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1b40ec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['circular_n_genes_2000',\n",
       " 'elliptical_distant_n_genes_2000',\n",
       " 'elliptical_n_genes_2000',\n",
       " 'intersecting_diagonal_n_genes_2000',\n",
       " 'intersecting_diagonal_more_points_intersect_n_genes_2000']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenarios = [\n",
    "    \"circular_n_genes_2000\",\n",
    "    \"elliptical_distant_n_genes_2000\",\n",
    "    \"elliptical_n_genes_2000\",\n",
    "    \"intersecting_diagonal_n_genes_2000\",\n",
    "    \"intersecting_diagonal_more_points_intersect_n_genes_2000\"\n",
    "]\n",
    "\n",
    "scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d42d71b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#Batch1',\n",
       " '#Batch0',\n",
       " 'weight',\n",
       " 'KL loc|glob',\n",
       " 'max KL loc|glob',\n",
       " 'nKL loc|glob',\n",
       " 'wKL loc|glob',\n",
       " 'wnKL loc|glob',\n",
       " 'KL glob|loc',\n",
       " 'max KL glob|loc',\n",
       " 'nKL glob|loc',\n",
       " 'wKL glob|loc',\n",
       " 'wnKL glob|loc',\n",
       " 'JS Dist',\n",
       " 'max JS Dist',\n",
       " 'nJS Dist',\n",
       " 'wJS Dist',\n",
       " 'wnJS Dist',\n",
       " 'JS Div',\n",
       " 'max JS Div',\n",
       " 'nJS Div',\n",
       " 'wJS Div',\n",
       " 'wnJS Div',\n",
       " 'TV',\n",
       " 'max TV',\n",
       " 'nTV',\n",
       " 'wTV',\n",
       " 'wnTV',\n",
       " 'H',\n",
       " 'max H',\n",
       " 'nH',\n",
       " 'wH',\n",
       " 'wnH',\n",
       " 'chiSD',\n",
       " 'max chiSD',\n",
       " 'nChiSD',\n",
       " 'wChiSD',\n",
       " 'wnChiSD',\n",
       " 'WD',\n",
       " 'max WD',\n",
       " 'nWD',\n",
       " 'wWD',\n",
       " 'wnWD',\n",
       " 'cLISI',\n",
       " 'iLISI',\n",
       " 'n_iLISI',\n",
       " 'w_nILISI',\n",
       " 'ASW',\n",
       " '1-ASW',\n",
       " 'wASW',\n",
       " 'kBET',\n",
       " 'wkBET',\n",
       " 'PCR',\n",
       " 'graph_conn',\n",
       " '1-graph_conn',\n",
       " 'wGraph_conn',\n",
       " 'isolated_labels_f1',\n",
       " 'isolated_labels_asw']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adjust col_order based on the dataset\n",
    "col_order = [\n",
    "    '#Batch1',     '#Batch0',           'weight',\n",
    "    'KL loc|glob',  'max KL loc|glob',  'nKL loc|glob', 'wKL loc|glob', 'wnKL loc|glob',\n",
    "    'KL glob|loc',  'max KL glob|loc',  'nKL glob|loc', 'wKL glob|loc', 'wnKL glob|loc',\n",
    "    'JS Dist',      'max JS Dist',      'nJS Dist',     'wJS Dist',     'wnJS Dist',\n",
    "    'JS Div',       'max JS Div',       'nJS Div',      'wJS Div',      'wnJS Div',\n",
    "    'TV',           'max TV',           'nTV',          'wTV',          'wnTV', \n",
    "    'H',            'max H',            'nH',           'wH',           'wnH', \n",
    "    'chiSD',        'max chiSD',        'nChiSD',       'wChiSD',       'wnChiSD',\n",
    "    'WD',           'max WD',           'nWD',          'wWD',          'wnWD',\n",
    "    'cLISI',\n",
    "    'iLISI',        'n_iLISI',          'w_nILISI',\n",
    "    'ASW',          '1-ASW',            'wASW',\n",
    "    'kBET',         'wkBET',            'PCR',\n",
    "    'graph_conn',   '1-graph_conn',     'wGraph_conn',\n",
    "    'isolated_labels_f1',               'isolated_labels_asw'\n",
    "    ]\n",
    "\n",
    "col_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8533f952",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e54f0085",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(df, k=90, metric=\"euclidean\", include_self=False):\n",
    "    \"\"\"\n",
    "    Finds k-nearest neighbors for each cell.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame (rows=cells, cols=features)\n",
    "    k : # neighbors to return per cell\n",
    "    metric : 'euclidean', 'cosine' etc\n",
    "    include_self : True or False; include the cell itself as its 1st neighbor\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    indices : np.array()\n",
    "        indices of k-nearest neighbors for each cell\n",
    "    distances : np.array()\n",
    "        distances of k-nearest neighbors for each cell\n",
    "    \"\"\"\n",
    "    # if we are not including cell itself add extra neighbor\n",
    "    # because NearestNeighbors by default include itself as neighbor\n",
    "    k = k if include_self else k + 1\n",
    "\n",
    "    X = df.to_numpy(dtype=np.float32, copy=False)\n",
    "\n",
    "    nn = NearestNeighbors(\n",
    "        n_neighbors=k,\n",
    "        metric=metric,\n",
    "        algorithm='auto',\n",
    "        n_jobs=-1   # use all cores\n",
    "    ).fit(X)\n",
    "    \n",
    "    distances, indices = nn.kneighbors(X, return_distance=True)\n",
    "\n",
    "    # drop cell itself from neighbors\n",
    "    if not include_self:\n",
    "        distances = distances[:, 1:]\n",
    "        indices = indices[:, 1:]\n",
    "\n",
    "    return indices, distances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb437988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_dists_to_same_type_cells(pca_coords, cell_types):\n",
    "    \"\"\"\n",
    "    Calculate the mean distance of each cell to other cells of the same type.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    pca_coords : np.ndarray\n",
    "        PCA coordinates matrix (cells x 50).\n",
    "    cell_types : pd.Series\n",
    "        Series containing the cell type for each cell.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Array of mean distances for each cell to other cells of the same type.\n",
    "    \"\"\"\n",
    "\n",
    "    mean_dists = np.zeros(pca_coords.shape[0])\n",
    "\n",
    "    for cell_type in cell_types.unique():\n",
    "        \n",
    "        mask = cell_types == cell_type\n",
    "        type_expression = pca_coords[mask]\n",
    "\n",
    "        # calculate all pairwise distances for the current cell type\n",
    "        dists = cdist(type_expression, type_expression, metric='euclidean')\n",
    "\n",
    "        # mean excluding diagonal (self-distances)\n",
    "        np.fill_diagonal(dists, np.nan)\n",
    "        type_mean_dists = np.nanmean(dists, axis=1)\n",
    "\n",
    "        # assign back to original positions\n",
    "        mean_dists[mask] = type_mean_dists\n",
    "\n",
    "    \n",
    "    min_dist = np.nanmin(mean_dists)\n",
    "\n",
    "    # normalize distances so the minimum distance is 1\n",
    "    normalized_dists = mean_dists / min_dist\n",
    "    \n",
    "    return normalized_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6dee7410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust it\n",
    "\n",
    "def plot_emb_and_distrs(\n",
    "        scenario, coords,\n",
    "        cell_types, batches,\n",
    "        local_dist, global_dist,\n",
    "        out_file, emb=\"pca\",\n",
    "        local_dist_k60=None, local_dist_k30=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot\n",
    "    - 1st row: UMAP/PCA in square frame\n",
    "    - 2nd row: global distr (left) and local k=90 by source batch (right)\n",
    "    - 3rd row: local k=60 (left) and local k=30 (right), both by source batch\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    scenario : str\n",
    "        The name of the scenario being analyzed.\n",
    "    coords : np.ndarray\n",
    "        UMAP/PCA coordinates (cells x 2).\n",
    "    cell_types : pd.Series\n",
    "        Series containing the cell type for each cell.\n",
    "    batches : pd.Series\n",
    "        Series containing the batch information for each cell.\n",
    "    local_dist : pd.DataFrame\n",
    "        Batch composition of each cell's neighborhood (k=90)\n",
    "    global_dist : pd.DataFrame\n",
    "        Cell IDs are stored in indices and columns are unique batch labels\n",
    "    out_file : str\n",
    "        Output file path for the plot.\n",
    "    emb : str\n",
    "        Embedding method used ('umap' or 'pca')\n",
    "    local_dist_k60 : pd.DataFrame\n",
    "        Batch composition of each cell's neighborhood (k=60)\n",
    "    local_dist_k30 : pd.DataFrame\n",
    "        Batch composition of each cell's neighborhood (k=30)\n",
    "    \"\"\"\n",
    "\n",
    "    # color palette and markers\n",
    "    base_palette = list(plt.cm.Set1.colors)\n",
    "    markers = ['o', 's', '^', 'v', '<', '>', 'D', 'p', 'h', '*', '+', 'x', '|', '_', '.', '1', '2', '3', '4', '8', 'H', 'P']\n",
    "\n",
    "    unique_batches = sorted(batches.unique())\n",
    "    unique_cell_types = sorted(cell_types.unique())\n",
    "    batch_cols = list(local_dist.columns)   # column order for stacked bars\n",
    "\n",
    "    # unified batch_to_color mapping for all subplots\n",
    "    ordered_batches = batch_cols + [b for b in unique_batches if b not in batch_cols]\n",
    "    # cycle through Set1 if more batches than colors\n",
    "    batch_to_color = {b: base_palette[i % len(base_palette)] for i, b in enumerate(ordered_batches)}\n",
    "\n",
    "    # figure and layout; 3 rows \n",
    "    fig = plt.figure(figsize=(16, 18))\n",
    "    outer = fig.add_gridspec(3, 1, height_ratios=[3, 1, 1], hspace=0.45)\n",
    "\n",
    "    # 1st row: full width (pca/umap)\n",
    "    ax = fig.add_subplot(outer[0])\n",
    "\n",
    "    # 2nd row: global distr (left) and local k=90 (right), with gutters\n",
    "    row2 = outer[1].subgridspec(1, 4, wspace=0.25, width_ratios=[0.6, 1.0, 1.0, 0.6])\n",
    "    ax_global    = fig.add_subplot(row2[1])    # left plot\n",
    "    ax_local_k90 = fig.add_subplot(row2[2]) # right plot\n",
    "\n",
    "    # 3rd row: k=60 (left) and k=30 (right)\n",
    "    row3 = outer[2].subgridspec(1, 4, wspace=0.25, width_ratios=[0.6, 1.0, 1.0, 0.6])\n",
    "    ax_k60 = fig.add_subplot(row3[1])\n",
    "    ax_k30 = fig.add_subplot(row3[2])\n",
    "\n",
    "    # scatter (pca/umap)\n",
    "    for i, batch in enumerate(unique_batches):\n",
    "        for j, ct in enumerate(unique_cell_types):\n",
    "            mask = (batches == batch) & (cell_types == ct)\n",
    "            # only plot if there are cells\n",
    "            if not np.any(mask):\n",
    "                continue\n",
    "            pts = coords[mask]\n",
    "\n",
    "            \"\"\"\n",
    "            # subsample if too many points\n",
    "            if pts.shape[0] > 200:\n",
    "                np.random.seed(42)\n",
    "                idx = np.random.choice(pts.shape[0], 200, replace=False)\n",
    "                pts = pts[idx]\n",
    "            \"\"\"\n",
    "\n",
    "            ax.scatter(\n",
    "                pts[:, 0], pts[:, 1],\n",
    "                c=batch_to_color[batch],\n",
    "                marker=markers[j%len(markers)],\n",
    "                s=20,                        # Slightly larger size makes shape distinguishable\n",
    "                alpha=0.6,                   # Higher alpha helps shape pop, still keeps density visible\n",
    "                edgecolors='black',         # Brings out marker shape\n",
    "                linewidth=0.2,              # Thin border for definition without being distracting\n",
    "                zorder=2,\n",
    "                rasterized=True,            # Keep it if exporting to PDF\n",
    "                label=f'{batch}_{ct}' if i == 0 and j == 0 else \"\"\n",
    "            )\n",
    "\n",
    "    # square box for scatter plot\n",
    "    x_min, x_max = coords[:, 0].min(), coords[:, 0].max()\n",
    "    y_min, y_max = coords[:, 1].min(), coords[:, 1].max()\n",
    "    x_c = 0.5 * (x_min + x_max); y_c = 0.5 * (y_min + y_max)\n",
    "    span = max(x_max - x_min, y_max - y_min); pad = 0.05 * span; half = 0.5 * span + pad\n",
    "    ax.set_xlim(x_c - half, x_c + half); ax.set_ylim(y_c - half, y_c + half)\n",
    "    ax.set_box_aspect(1)\n",
    "\n",
    "    # legends\n",
    "    batch_legend = [\n",
    "        plt.Line2D([0], [0], marker='o', color='w',\n",
    "                   markerfacecolor=batch_to_color[b],\n",
    "                   markersize=8, label=b)\n",
    "        for b in ordered_batches\n",
    "    ]\n",
    "    celltype_legend = [\n",
    "        plt.Line2D([0], [0], marker=markers[j % len(markers)],\n",
    "                   color='white', markeredgecolor='black',\n",
    "                   markersize=8, label=ct, linestyle='None')\n",
    "        for j, ct in enumerate(unique_cell_types)\n",
    "    ]\n",
    "    leg1 = ax.legend(handles=batch_legend, title='Batch',\n",
    "                     loc='upper left', bbox_to_anchor=(1.02, 1),\n",
    "                     fontsize=10, title_fontsize=11)\n",
    "    leg2 = ax.legend(handles=celltype_legend, title='Cell type',\n",
    "                     loc='upper left', bbox_to_anchor=(1.02, 0.6),\n",
    "                     fontsize=10, title_fontsize=11)\n",
    "    ax.add_artist(leg1)\n",
    "\n",
    "    # ax.set_title(f\"Sc_{scenario} (facLoc={facloc}, facScale={facscale}); {emb}: Batch (colors) & Cell Type (markers)\", fontsize=10)\n",
    "    ax.set_title(f\"Sc_{scenario}; {emb}: Batch (colors) & Cell Type (markers)\", fontsize=10)\n",
    "    ax.set_xticks([]); ax.set_yticks([])\n",
    "    ax.set_xlabel(f\"{emb} 1\", fontsize=10)\n",
    "    ax.set_ylabel(f\"{emb} 2\", fontsize=10)\n",
    "\n",
    "    # helpers\n",
    "    def _local_props_by_source(local_df):\n",
    "        \"\"\"Average neighbor composition per (celltype, source_batch) then row-normalize\"\"\"\n",
    "        # ensure same columns/order as batch_cols\n",
    "        local_df = local_df.reindex(columns=batch_cols, fill_value=0)\n",
    "        tmp = local_df.copy()\n",
    "        tmp[\"celltype\"] = cell_types.values\n",
    "        tmp[\"source_batch\"] = batches.values\n",
    "        means = tmp.groupby([\"celltype\", \"source_batch\"])[batch_cols].mean()\n",
    "        props = means.div(means.sum(axis=1), axis=0).fillna(0)\n",
    "\n",
    "        # order bars\n",
    "        idx = []\n",
    "        for ct in unique_cell_types:\n",
    "            for b in ordered_batches:\n",
    "                idx.append((ct, b))\n",
    "        if idx:\n",
    "            props = props.loc[idx]\n",
    "        return props\n",
    "    \n",
    "    def _plot_local_props(ax_, props, title):\n",
    "        props.plot(kind=\"bar\", stacked=True, ax=ax_,\n",
    "                   color=[batch_to_color[b] for b in batch_cols],\n",
    "                   width=0.85, legend=False)\n",
    "        ax_.set_title(title, fontsize=10)\n",
    "        ax_.set_ylabel(\"Proportion of Neighbors\", fontsize=9)\n",
    "        ax_.set_xlabel(\"group (source batch)\", fontsize=9)\n",
    "        ax_.set_xticklabels([f\"{ct}\\n({sb})\" for (ct, sb) in props.index],\n",
    "                            rotation=90, ha=\"right\")\n",
    "        ax_.grid(axis='y', alpha=0.3)\n",
    "        ax_.tick_params(axis=\"x\", labelsize=7)\n",
    "        ax_.tick_params(axis=\"y\", labelsize=7)\n",
    "\n",
    "    # 2nd row: global (left)\n",
    "    global_with_type = global_dist.reindex(columns=batch_cols, fill_value=0).copy()\n",
    "    global_with_type[\"celltype\"] = cell_types.values\n",
    "    global_means = global_with_type.groupby(\"celltype\")[batch_cols].mean()\n",
    "    global_props = global_means.div(global_means.sum(axis=1), axis=0).fillna(0)\n",
    "    global_props.plot(kind=\"bar\", stacked=True, ax=ax_global,\n",
    "                      color=[batch_to_color[b] for b in batch_cols],\n",
    "                      width=0.85, legend=False)\n",
    "    ax_global.set_title(\"Global distribution\", fontsize=10)\n",
    "    ax_global.set_ylabel(\"Proportion of Cells\", fontsize=9)\n",
    "    ax_global.set_xlabel(\"celltype\", fontsize=9)\n",
    "    ax_global.tick_params(axis=\"x\", rotation=90, labelsize=7)\n",
    "    ax_global.tick_params(axis=\"y\", labelsize=7)\n",
    "    ax_global.grid(axis='y', alpha=0.3)\n",
    "\n",
    "    # 2nd row: local k=90 (right)\n",
    "    props90 = _local_props_by_source(local_df=local_dist)\n",
    "    _plot_local_props(ax_=ax_local_k90, props=props90, title=\"Local (k=90): by source batch\")\n",
    "\n",
    "    # 3rd row: local k=60 (left) and k=30 (right)\n",
    "    if local_dist_k60 is not None:\n",
    "        props60 = _local_props_by_source(local_dist_k60)\n",
    "        _plot_local_props(ax_=ax_k60, props=props60, title=\"Local (k=60): by source batch\")\n",
    "    else:\n",
    "        ax_k60.axis('off')\n",
    "        ax_k60.text(0.5, 0.5, \"local_dist_k60 not provided\",\n",
    "                    ha='center', va='center', fontsize=10)\n",
    "        \n",
    "    if local_dist_k30 is not None:\n",
    "        props30 = _local_props_by_source(local_dist_k30)\n",
    "        _plot_local_props(ax_=ax_k30, props=props30, title=\"Local (k=30): by source batch\")\n",
    "    else:\n",
    "        ax_k30.axis('off')\n",
    "        ax_k30.text(0.5, 0.5, \"local_dist_k30 not provided\",\n",
    "                    ha='center', va='center', fontsize=10)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_file, dpi=300, bbox_inches=\"tight\")\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d018ddb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_emb_and_distrs_pub(\n",
    "        scenario, coords,\n",
    "        cell_types, batches,\n",
    "        local_dist, global_dist,\n",
    "        out_file, emb=\"pca\",\n",
    "        local_dist_k60=None, local_dist_k30=None,\n",
    "        export_png=False, png_dpi=600\n",
    "):\n",
    "    \"\"\"\n",
    "    Nature-ready layout with horizontal bars for rows 2 & 3\n",
    "    Row1 (A): Embedding (square)\n",
    "    Row2 (B,C): Global distribution (barh) | Local k=90 (barh)\n",
    "    Row3 (D,E): Local k=60 (barh) | Local k=30 (barh)\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Palette: Okabe–Ito (colorblind-safe) ---\n",
    "    okabe_ito = [\"#0072B2\", \"#E69F00\", \"#009E73\", \"#D55E00\",\n",
    "                 \"#CC79A7\", \"#56B4E9\", \"#F0E442\", \"#000000\"]\n",
    "\n",
    "    unique_batches = list(pd.Index(batches.unique()).sort_values())\n",
    "    unique_cell_types = list(pd.Index(cell_types.unique()).sort_values())\n",
    "\n",
    "    # Preserve incoming local_dist column order, then append any missing batches\n",
    "    batch_cols = list(local_dist.columns)\n",
    "    ordered_batches = batch_cols + [b for b in unique_batches if b not in batch_cols]\n",
    "    batch_to_color = {b: okabe_ito[i % len(okabe_ito)] for i, b in enumerate(ordered_batches)}\n",
    "\n",
    "    # Figure (let the mplstyle control figure size)\n",
    "    fig = plt.figure(constrained_layout=True)\n",
    "    outer = fig.add_gridspec(3, 1, height_ratios=[3.2, 1.6, 1.6])\n",
    "\n",
    "    # Axes\n",
    "    ax = fig.add_subplot(outer[0])\n",
    "    row2 = outer[1].subgridspec(1, 2, wspace=0.3)\n",
    "    ax_global    = fig.add_subplot(row2[0])\n",
    "    ax_local_k90 = fig.add_subplot(row2[1])\n",
    "    row3 = outer[2].subgridspec(1, 2, wspace=0.3)\n",
    "    ax_k60 = fig.add_subplot(row3[0])\n",
    "    ax_k30 = fig.add_subplot(row3[1])\n",
    "\n",
    "    # ----- Embedding scatter: batch=color, cell type=marker -----\n",
    "    markers = ['o', 's', '^', 'v', '<', '>', 'D', 'p', 'h', '*', '+', 'x', 'P', 'H', '1', '2', '3', '4', '.', '|', '_']\n",
    "    for j, ct in enumerate(unique_cell_types):\n",
    "        for i, b in enumerate(unique_batches):\n",
    "            mask = (cell_types == ct) & (batches == b)\n",
    "            if not np.any(mask):\n",
    "                continue\n",
    "            pts = coords[mask.values] if isinstance(mask, pd.Series) else coords[mask]\n",
    "            ax.scatter(\n",
    "                pts[:, 0], pts[:, 1],\n",
    "                s=10,\n",
    "                marker=markers[j % len(markers)],\n",
    "                facecolors=batch_to_color[b],\n",
    "                edgecolors='black', linewidths=0.15,\n",
    "                alpha=0.85, zorder=2, rasterized=True\n",
    "            )\n",
    "\n",
    "    # Square frame\n",
    "    x_min, x_max = np.min(coords[:, 0]), np.max(coords[:, 0])\n",
    "    y_min, y_max = np.min(coords[:, 1]), np.max(coords[:, 1])\n",
    "    x_c, y_c = 0.5 * (x_min + x_max), 0.5 * (y_min + y_max)\n",
    "    span = max(x_max - x_min, y_max - y_min)\n",
    "    pad = 0.05 * span\n",
    "    half = 0.5 * span + pad\n",
    "    ax.set_xlim(x_c - half, x_c + half)\n",
    "    ax.set_ylim(y_c - half, y_c + half)\n",
    "    ax.set_box_aspect(1)\n",
    "    ax.set_xticks([]); ax.set_yticks([])\n",
    "    ax.set_xlabel(f\"{emb} 1\"); ax.set_ylabel(f\"{emb} 2\")\n",
    "\n",
    "    # Shared legends (outside)\n",
    "    batch_handles = [Line2D([0], [0], marker='o', linestyle='None',\n",
    "                            markerfacecolor=batch_to_color[b], markeredgecolor='black',\n",
    "                            markersize=6, label=b)\n",
    "                     for b in ordered_batches]\n",
    "    ct_handles = [Line2D([0], [0],\n",
    "                         marker=markers[j % len(markers)], linestyle='None',\n",
    "                         markerfacecolor='white', markeredgecolor='black',\n",
    "                         markersize=6, label=ct)\n",
    "                  for j, ct in enumerate(unique_cell_types)]\n",
    "    leg1 = ax.legend(handles=batch_handles, title=\"Batch\",\n",
    "                     loc='upper left', bbox_to_anchor=(1.02, 1.0), borderaxespad=0.)\n",
    "    leg2 = ax.legend(handles=ct_handles, title=\"Cell type\",\n",
    "                     loc='upper left', bbox_to_anchor=(1.02, 0.62), borderaxespad=0.)\n",
    "    ax.add_artist(leg1)\n",
    "\n",
    "    # Panel label\n",
    "    ax.text(-0.08, 1.02, \"A\", transform=ax.transAxes,\n",
    "            fontsize=11, fontweight='bold', va='bottom', ha='right')\n",
    "\n",
    "    # ----- Helpers -----\n",
    "    def _local_props_by_source(local_df):\n",
    "        \"\"\"Average neighbor composition per (celltype, source_batch) then row-normalize.\"\"\"\n",
    "        local_df = local_df.reindex(columns=ordered_batches, fill_value=0)\n",
    "        tmp = local_df.copy()\n",
    "        tmp[\"celltype\"] = cell_types.values\n",
    "        tmp[\"source_batch\"] = batches.values\n",
    "        means = tmp.groupby([\"celltype\", \"source_batch\"])[ordered_batches].mean()\n",
    "        props = means.div(means.sum(axis=1), axis=0).fillna(0)\n",
    "\n",
    "        # Order rows as (ct, batch) if they exist\n",
    "        ordered_idx = []\n",
    "        for ct in unique_cell_types:\n",
    "            for b in ordered_batches:\n",
    "                key = (ct, b)\n",
    "                if key in props.index:\n",
    "                    ordered_idx.append(key)\n",
    "        if ordered_idx:\n",
    "            props = props.loc[ordered_idx]\n",
    "        return props\n",
    "\n",
    "    def _plot_local_props_h(ax_, props):\n",
    "        \"\"\"Horizontal stacked bars for local distributions.\"\"\"\n",
    "        props.plot(kind=\"barh\", stacked=True, ax=ax_,\n",
    "                   color=[batch_to_color[b] for b in ordered_batches],\n",
    "                   width=0.85, legend=False)\n",
    "        ax_.set_xlabel(\"Proportion\")\n",
    "        ax_.set_ylabel(\"\")\n",
    "        # y tick labels from MultiIndex (ct, source_batch)\n",
    "        ylabels = [f\"{ct} ({sb})\" for (ct, sb) in props.index]\n",
    "        ax_.set_yticklabels(ylabels)\n",
    "        ax_.set_xlim(0.0, 1.0)\n",
    "        ax_.grid(axis='x', alpha=0.25)\n",
    "\n",
    "    # ----- Row 2: Global (B) & Local k=90 (C) — HORIZONTAL -----\n",
    "    global_with_type = global_dist.reindex(columns=ordered_batches, fill_value=0).copy()\n",
    "    global_with_type[\"celltype\"] = cell_types.values\n",
    "    global_means = global_with_type.groupby(\"celltype\")[ordered_batches].mean()\n",
    "    global_props = global_means.div(global_means.sum(axis=1), axis=0).fillna(0)\n",
    "\n",
    "    global_props.plot(kind=\"barh\", stacked=True, ax=ax_global,\n",
    "                      color=[batch_to_color[b] for b in ordered_batches],\n",
    "                      width=0.85, legend=False)\n",
    "    ax_global.set_xlabel(\"Proportion\")\n",
    "    ax_global.set_ylabel(\"\")\n",
    "    ax_global.set_yticklabels(list(global_props.index))\n",
    "    ax_global.set_xlim(0.0, 1.0)\n",
    "    ax_global.grid(axis='x', alpha=0.25)\n",
    "    ax_global.text(-0.12, 1.02, \"B\", transform=ax_global.transAxes,\n",
    "                   fontsize=11, fontweight='bold', va='bottom', ha='right')\n",
    "\n",
    "    props90 = _local_props_by_source(local_dist)\n",
    "    _plot_local_props_h(ax_local_k90, props90)\n",
    "    ax_local_k90.text(-0.12, 1.02, \"C\", transform=ax_local_k90.transAxes,\n",
    "                      fontsize=11, fontweight='bold', va='bottom', ha='right')\n",
    "\n",
    "    # ----- Row 3: Local k=60 (D) & k=30 (E) — HORIZONTAL -----\n",
    "    if local_dist_k60 is not None:\n",
    "        props60 = _local_props_by_source(local_dist_k60)\n",
    "        _plot_local_props_h(ax_k60, props60)\n",
    "    else:\n",
    "        ax_k60.axis('off')\n",
    "        ax_k60.text(0.5, 0.5, \"k=60 not provided\", ha='center', va='center')\n",
    "    ax_k60.text(-0.12, 1.02, \"D\", transform=ax_k60.transAxes,\n",
    "                fontsize=11, fontweight='bold', va='bottom', ha='right')\n",
    "\n",
    "    if local_dist_k30 is not None:\n",
    "        props30 = _local_props_by_source(local_dist_k30)\n",
    "        _plot_local_props_h(ax_k30, props30)\n",
    "    else:\n",
    "        ax_k30.axis('off')\n",
    "        ax_k30.text(0.5, 0.5, \"k=30 not provided\", ha='center', va='center')\n",
    "    ax_k30.text(-0.12, 1.02, \"E\", transform=ax_k30.transAxes,\n",
    "                fontsize=11, fontweight='bold', va='bottom', ha='right')\n",
    "\n",
    "    # ----- Export: vector PDF (preferred) + optional PNG -----\n",
    "    pdf_path = out_file if out_file.lower().endswith(\".pdf\") else out_file + \".pdf\"\n",
    "    fig.savefig(pdf_path, bbox_inches=\"tight\")\n",
    "    if export_png:\n",
    "        png_path = out_file if out_file.lower().endswith(\".png\") else out_file + \".png\"\n",
    "        fig.savefig(png_path, dpi=png_dpi, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6b7eda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_emb_and_global_pub(\n",
    "        scenario, coords,\n",
    "        cell_types, batches,\n",
    "        local_dist, global_dist,\n",
    "        out_file, emb=\"pca\",\n",
    "        local_dist_k60=None, local_dist_k30=None,\n",
    "        export_png=False, png_dpi=600,\n",
    "        sort_by_total=False, ascending=False,\n",
    "        bar_width=0.4,           # slimmer grouped bars (default 0.6)\n",
    "        legend_col_width=0.32    # width fraction for right legend column\n",
    "):\n",
    "    \"\"\"\n",
    "    Nature-ready: ONLY embedding + grouped COUNT bars.\n",
    "    A and B are EXACTLY aligned in width by:\n",
    "      - placing both in the same left GridSpec column,\n",
    "      - disabling constrained_layout,\n",
    "      - and hard-locking their left/right positions to the left-column cell.\n",
    "    \"\"\"\n",
    "\n",
    "    # ---- Palette: Okabe–Ito (colorblind-safe) ----\n",
    "    okabe_ito = [\"#0072B2\", \"#E69F00\", \"#009E73\", \"#D55E00\",\n",
    "                 \"#CC79A7\", \"#56B4E9\", \"#F0E442\", \"#000000\"]\n",
    "\n",
    "    # Entities\n",
    "    unique_batches = list(pd.Index(batches.unique()).sort_values())\n",
    "    unique_cell_types = list(pd.Index(cell_types.unique()).sort_values())\n",
    "\n",
    "    # Series order for grouped bars\n",
    "    if isinstance(global_dist, pd.DataFrame) and len(global_dist.columns) > 0:\n",
    "        ordered_batches = list(global_dist.columns) + [b for b in unique_batches if b not in global_dist.columns]\n",
    "    else:\n",
    "        ordered_batches = unique_batches\n",
    "\n",
    "    batch_to_color = {b: okabe_ito[i % len(okabe_ito)] for i, b in enumerate(ordered_batches)}\n",
    "\n",
    "    # ===== Figure / Grid =====\n",
    "    fig = plt.figure(constrained_layout=False)  # we'll manage layout manually\n",
    "    gs = fig.add_gridspec(\n",
    "        nrows=2, ncols=2,\n",
    "        width_ratios=[1.0, legend_col_width],   # left = plots, right = legends\n",
    "        height_ratios=[1.0, 1.0]\n",
    "    )\n",
    "    # Fixed margins; legends won’t compress plot widths\n",
    "    fig.subplots_adjust(left=0.10, right=0.90, top=0.98, bottom=0.12, hspace=0.28, wspace=0.15)\n",
    "\n",
    "    ax_emb = fig.add_subplot(gs[0, 0])   # A (embedding)\n",
    "    ax_bar = fig.add_subplot(gs[1, 0])   # B (grouped bars)\n",
    "    ax_leg = fig.add_subplot(gs[:, 1])   # legends column (spans both rows)\n",
    "    ax_leg.axis(\"off\")\n",
    "\n",
    "    # ===== Panel A: Embedding (square) =====\n",
    "    markers = ['o', 's', '^', 'v', '<', '>', 'D', 'p', 'h', '*', '+', 'x', 'P', 'H', '1', '2', '3', '4', '.', '|', '_']\n",
    "    for j, ct in enumerate(unique_cell_types):\n",
    "        for b in unique_batches:\n",
    "            mask = (cell_types == ct) & (batches == b)\n",
    "            if not np.any(mask):\n",
    "                continue\n",
    "            pts = coords[mask.values] if isinstance(mask, pd.Series) else coords[mask]\n",
    "            ax_emb.scatter(\n",
    "                pts[:, 0], pts[:, 1],\n",
    "                s=10,\n",
    "                marker=markers[j % len(markers)],\n",
    "                facecolors=batch_to_color[b],\n",
    "                edgecolors='black', linewidths=0.15,\n",
    "                alpha=0.85, zorder=2, rasterized=True\n",
    "            )\n",
    "\n",
    "    # Square frame (uses full left-column width)\n",
    "    x_min, x_max = np.min(coords[:, 0]), np.max(coords[:, 0])\n",
    "    y_min, y_max = np.min(coords[:, 1]), np.max(coords[:, 1])\n",
    "    x_c, y_c = 0.5 * (x_min + x_max), 0.5 * (y_min + y_max)\n",
    "    span = max(x_max - x_min, y_max - y_min); pad = 0.05 * span; half = 0.5 * span + pad\n",
    "    ax_emb.set_xlim(x_c - half, x_c + half)\n",
    "    ax_emb.set_ylim(y_c - half, y_c + half)\n",
    "    ax_emb.set_box_aspect(1)\n",
    "    ax_emb.set_xticks([]); ax_emb.set_yticks([])\n",
    "    # ax_emb.set_xlabel(f\"{emb} 1\"); ax_emb.set_ylabel(f\"{emb} 2\")\n",
    "    ax_emb.set_xlabel(\"emb 1\"); ax_emb.set_ylabel(\"emb 2\")\n",
    "    ax_emb.text(-0.08, 1.02, \"A\", transform=ax_emb.transAxes,\n",
    "                fontsize=11, fontweight='bold', va='bottom', ha='right')\n",
    "\n",
    "    # ===== Panel B: Grouped vertical COUNT bars (x = cell types, y = counts) =====\n",
    "    counts = pd.crosstab(cell_types, batches).reindex(\n",
    "        index=unique_cell_types, columns=ordered_batches, fill_value=0\n",
    "    )\n",
    "    if sort_by_total:\n",
    "        counts = counts.loc[counts.sum(axis=1).sort_values(ascending=ascending).index]\n",
    "\n",
    "    # Grouped bars (thinner width)\n",
    "    counts.plot(kind=\"bar\", stacked=False, ax=ax_bar,\n",
    "                color=[batch_to_color[b] for b in ordered_batches],\n",
    "                width=bar_width, legend=False)\n",
    "\n",
    "    ax_bar.set_ylabel(\"Cells (count)\")\n",
    "    ax_bar.set_xlabel(\"\")\n",
    "    ax_bar.set_xticklabels(list(counts.index), rotation=0, ha=\"center\")\n",
    "    ax_bar.grid(axis='y', alpha=0.25)\n",
    "    ax_bar.text(-0.12, 1.02, \"B\", transform=ax_bar.transAxes,\n",
    "                fontsize=11, fontweight='bold', va='bottom', ha='right')\n",
    "    ax_bar.margins(x=0.02)\n",
    "\n",
    "    # ===== Legends (right column) =====\n",
    "    batch_handles = [Line2D([0], [0], marker='o', linestyle='None',\n",
    "                            markerfacecolor=batch_to_color[b], markeredgecolor='black',\n",
    "                            markersize=6, label=b)\n",
    "                     for b in ordered_batches]\n",
    "    leg_batches = ax_leg.legend(handles=batch_handles, title=\"Batch\",\n",
    "                                loc='upper left', bbox_to_anchor=(0.0, 1.0),\n",
    "                                ncol=1, borderaxespad=0., frameon=False)\n",
    "    ax_leg.add_artist(leg_batches)\n",
    "\n",
    "    markerset = [Line2D([0], [0], marker=markers[j % len(markers)], linestyle='None',\n",
    "                        markerfacecolor='white', markeredgecolor='black',\n",
    "                        markersize=6, label=ct)\n",
    "                 for j, ct in enumerate(unique_cell_types)]\n",
    "    ax_leg.legend(handles=markerset, title=\"Cell type\",\n",
    "                  loc='upper left', bbox_to_anchor=(0.0, 0.60),\n",
    "                  ncol=1, borderaxespad=0., frameon=False)\n",
    "\n",
    "    # ===== Hard lock A & B to the SAME left/right =====\n",
    "    # Use the left-column grid cell as the authority for x0/x1 so both axes match exactly.\n",
    "    fig.canvas.draw()  # finalize initial layout\n",
    "    left_cell_bbox = gs[0, 0].get_position(fig)  # left column cell bbox\n",
    "    left_x0, left_x1 = left_cell_bbox.x0, left_cell_bbox.x1\n",
    "    # Preserve each axis' own y/height, but force identical left/right\n",
    "    for ax_ in (ax_emb, ax_bar):\n",
    "        p = ax_.get_position()\n",
    "        ax_.set_position([left_x0, p.y0, left_x1 - left_x0, p.height])\n",
    "\n",
    "    # ===== Export =====\n",
    "    pdf_path = out_file if out_file.lower().endswith(\".pdf\") else out_file + \".pdf\"\n",
    "    fig.savefig(pdf_path, bbox_inches=\"tight\")\n",
    "    if export_png:\n",
    "        png_path = out_file if out_file.lower().endswith(\".png\") else out_file + \".png\"\n",
    "        fig.savefig(png_path, dpi=png_dpi, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df42af24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_emb_and_global_pub_geom(\n",
    "    embeddings,                 # list of (emb_name, coords_nx2); expects >=2\n",
    "    cell_types,                 # list of pd.Series, aligned per embedding\n",
    "    batches,                    # list of pd.Series, aligned per embedding\n",
    "    out_file,\n",
    "    global_dist=None,           # optional; if provided, its columns define batch order\n",
    "    export_png=False, png_dpi=600,\n",
    "    sort_by_total=False, ascending=False,\n",
    "    bar_width=0.45,\n",
    "    square_global=True,\n",
    "    # NEW layout controls:\n",
    "    left=0.06, right=0.96, top=0.98, bottom=0.22, wspace=0.28,\n",
    "    # NEW legend spacing:\n",
    "    legend_dx=0.02,            # horizontal gap from panel C\n",
    "    legend_stack_gap=0.06      # vertical gap between the two legends (fig coords)\n",
    "):\n",
    "    \"\"\"\n",
    "    Nature-ready: 2 embeddings + 1 global distribution on a 1×3 grid.\n",
    "    Adds explicit subplot spacing and legend placement anchored to panel C.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Palette: Okabe–Ito (colorblind-safe) ---\n",
    "    okabe_ito = [\"#0072B2\", \"#E69F00\", \"#009E73\", \"#D55E00\",\n",
    "                 \"#CC79A7\", \"#56B4E9\", \"#F0E442\", \"#000000\"]\n",
    "\n",
    "    # --- Checks ---\n",
    "    assert len(embeddings) >= 2, \"Need at least 2 embeddings.\"\n",
    "    assert len(cell_types) >= 2 and len(batches) >= 2, \"cell_types/batches must be lists with >=2 items.\"\n",
    "\n",
    "    # Category order from the FIRST embedding\n",
    "    unique_cell_types = list(pd.Index(cell_types[0].unique()).sort_values())\n",
    "    unique_batches = list(pd.Index(batches[0].unique()).sort_values())\n",
    "\n",
    "    # Batch order (respect global_dist cols if given)\n",
    "    if isinstance(global_dist, pd.DataFrame) and len(global_dist.columns) > 0:\n",
    "        ordered_batches = list(global_dist.columns) + [b for b in unique_batches if b not in global_dist.columns]\n",
    "    else:\n",
    "        ordered_batches = unique_batches\n",
    "\n",
    "    batch_to_color = {b: okabe_ito[i % len(okabe_ito)] for i, b in enumerate(ordered_batches)}\n",
    "\n",
    "    # Stable marker per cell type\n",
    "    markers = ['o', 's', '^', 'v', '<', '>', 'D', 'p', 'h', '*', '+', 'x', 'P', 'H', '1', '2', '3', '4', '.', '|', '_']\n",
    "    ct_to_marker = {ct: markers[i % len(markers)] for i, ct in enumerate(unique_cell_types)}\n",
    "\n",
    "    # --- Figure / axes ---\n",
    "    fig, (axA, axB, axC) = plt.subplots(nrows=1, ncols=3, constrained_layout=False)\n",
    "    # More space between subplots + generous bottom for x-tick labels\n",
    "    fig.subplots_adjust(left=left, right=right, top=top, bottom=bottom, wspace=wspace)\n",
    "\n",
    "    # ===== Embedding panels A & B (square) =====\n",
    "    for idx, ((emb_name, coords), ax) in enumerate(zip(embeddings[:2], (axA, axB))):\n",
    "        ct_series = cell_types[idx]\n",
    "        b_series  = batches[idx]\n",
    "        if coords.shape[0] != len(ct_series) or coords.shape[0] != len(b_series):\n",
    "            raise ValueError(f\"Embedding {emb_name}: coords, cell_types, batches must have same length.\")\n",
    "\n",
    "        for ct in unique_cell_types:\n",
    "            mask_ct = (ct_series == ct)\n",
    "            if not np.any(mask_ct):\n",
    "                continue\n",
    "            m = ct_to_marker[ct]\n",
    "            for b in ordered_batches:\n",
    "                mask = mask_ct & (b_series == b)\n",
    "                if not np.any(mask):\n",
    "                    continue\n",
    "                pts = coords[mask.values] if isinstance(mask, pd.Series) else coords[mask]\n",
    "                ax.scatter(\n",
    "                    pts[:, 0], pts[:, 1],\n",
    "                    s=10, marker=m,\n",
    "                    facecolors=batch_to_color[b],\n",
    "                    edgecolors='black', linewidths=0.15,\n",
    "                    alpha=0.85, zorder=2, rasterized=True\n",
    "                )\n",
    "\n",
    "        # square frame + clean axes\n",
    "        x_min, x_max = np.min(coords[:, 0]), np.max(coords[:, 0])\n",
    "        y_min, y_max = np.min(coords[:, 1]), np.max(coords[:, 1])\n",
    "        x_c, y_c = 0.5 * (x_min + x_max), 0.5 * (y_min + y_max)\n",
    "        span = max(x_max - x_min, y_max - y_min); pad = 0.05 * span; half = 0.5 * span + pad\n",
    "        ax.set_xlim(x_c - half, x_c + half); ax.set_ylim(y_c - half, y_c + half)\n",
    "        ax.set_box_aspect(1)              # square\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "        ax.set_xlabel(\"emb 1\"); ax.set_ylabel(\"emb 2\")\n",
    "        ax.text(-0.08, 1.02, \"A\" if idx == 0 else \"B\", transform=ax.transAxes,\n",
    "                fontsize=11, fontweight='bold', va='bottom', ha='right')\n",
    "\n",
    "    # ===== Global distribution C (grouped vertical counts) =====\n",
    "    counts = pd.crosstab(cell_types[0], batches[0]).reindex(\n",
    "        index=unique_cell_types, columns=ordered_batches, fill_value=0\n",
    "    )\n",
    "    if sort_by_total:\n",
    "        counts = counts.loc[counts.sum(axis=1).sort_values(ascending=ascending).index]\n",
    "\n",
    "    counts.plot(kind=\"bar\", stacked=False, ax=axC,\n",
    "                color=[batch_to_color[b] for b in ordered_batches],\n",
    "                width=bar_width, legend=False)\n",
    "\n",
    "    # headroom\n",
    "    ymax = float(counts.to_numpy().max()) * 1.05 if counts.size > 0 else 1.0\n",
    "    axC.set_ylim(0, ymax)\n",
    "\n",
    "    if square_global:\n",
    "        axC.set_box_aspect(1)  # square frame for the bar panel too\n",
    "\n",
    "    axC.set_ylabel(\"Cells (count)\")\n",
    "    axC.set_xlabel(\"\")\n",
    "    # rotate and right-anchor labels so they don’t collide\n",
    "    for lbl in axC.get_xticklabels():\n",
    "        lbl.set_rotation(0)\n",
    "        lbl.set_ha('right')\n",
    "        lbl.set_rotation_mode('anchor')\n",
    "    axC.tick_params(axis='x', pad=2)\n",
    "    axC.grid(axis='y', alpha=0.25)\n",
    "    axC.text(-0.12, 1.02, \"C\", transform=axC.transAxes,\n",
    "             fontsize=11, fontweight='bold', va='bottom', ha='right')\n",
    "\n",
    "    # ===== Place legends NEXT TO panel C, centered vertically =====\n",
    "    # Build handles\n",
    "    batch_handles = [Line2D([0], [0], marker='o', linestyle='None',\n",
    "                            markerfacecolor=batch_to_color[b], markeredgecolor='black',\n",
    "                            markersize=6, label=b)\n",
    "                     for b in ordered_batches]\n",
    "    ct_handles = [Line2D([0], [0], marker=ct_to_marker[ct], linestyle='None',\n",
    "                         markerfacecolor='white', markeredgecolor='black',\n",
    "                         markersize=6, label=ct)\n",
    "                  for ct in unique_cell_types]\n",
    "\n",
    "    # We need a draw pass so Axes positions are finalized\n",
    "    fig.canvas.draw()\n",
    "    posC = axC.get_position()     # in figure coordinates\n",
    "    x_leg = posC.x1 + legend_dx   # a bit to the right of panel C\n",
    "    y_mid = (posC.y0 + posC.y1) / 2.0\n",
    "\n",
    "    # Batch legend (upper, centered-left of the midline)\n",
    "    fig.legend(handles=batch_handles, title=\"Batch\",\n",
    "               loc='center left', bbox_to_anchor=(x_leg, y_mid + legend_stack_gap),\n",
    "               frameon=False, borderaxespad=0.)\n",
    "\n",
    "    # Cell-type legend (lower, centered-left)\n",
    "    fig.legend(handles=ct_handles, title=\"Cell type\",\n",
    "               loc='center left', bbox_to_anchor=(x_leg, y_mid - legend_stack_gap),\n",
    "               frameon=False, borderaxespad=0.)\n",
    "\n",
    "    # --- Export ---\n",
    "    pdf_path = out_file if out_file.lower().endswith(\".pdf\") else out_file + \".pdf\"\n",
    "    fig.savefig(pdf_path, bbox_inches=\"tight\")\n",
    "    if export_png:\n",
    "        png_path = out_file if out_file.lower().endswith(\".png\") else out_file + \".png\"\n",
    "        fig.savefig(png_path, dpi=png_dpi, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ff2e91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_distributions(adata, dknn_df, celltypes_df, batches_df):\n",
    "    \"\"\"\n",
    "    Build local and global distributions for each cell\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    adata : anndata object\n",
    "    dknn_df : pd.DataFrame\n",
    "        indices of k nearest neighbors for each cell    \n",
    "    celltypes_df : pd.DataFrame\n",
    "        Cell type label for each cell.\n",
    "    batches_df : pd.DataFrame\n",
    "        Batch label for each cell.\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "    pd.DataFrame, pd.DataFrame\n",
    "        Local and global distributions for each cell.\n",
    "    \"\"\"\n",
    "\n",
    "    k = len(dknn_df.columns)    # number of neighbors\n",
    "\n",
    "    # construct dataframes\n",
    "    # batches_neighbors_df      : holds the batch label of each neighbor for each cell\n",
    "    # celltypes_neighbors_df    : holds the cell type label of each neighbor for each cell\n",
    "    batches_neighbors_df = pd.DataFrame(index=dknn_df.index, columns=[i for i in range(0, k)])\n",
    "    celltypes_neighbors_df = pd.DataFrame(index=dknn_df.index, columns=[i for i in range(0, k)])\n",
    "\n",
    "    batches = adata[batches_neighbors_df.index].obs[\"Batch\"].values\n",
    "    celltypes = adata[celltypes_neighbors_df.index].obs[\"Group\"].values\n",
    "\n",
    "    for i in range(len(batches_neighbors_df.index)):\n",
    "        # get batch and celltype label of each neighbor\n",
    "        batches_neighbors_df.iloc[i] = batches[dknn_df.iloc[i].values]\n",
    "        celltypes_neighbors_df.iloc[i] = celltypes[dknn_df.iloc[i].values]\n",
    "\n",
    "    # local and global distibutions\n",
    "    local_dist = pd.DataFrame(0, index=batches_df.index, columns=batches.unique(), dtype=float)\n",
    "    global_dist = pd.DataFrame(0, index=batches_df.index, columns=batches.unique(), dtype=float)\n",
    "\n",
    "    for b in batches.unique():\n",
    "        print(type(b), b)\n",
    "        for idx, cell_id in enumerate(celltypes_neighbors_df.index):\n",
    "            cell_type = celltypes_df.iloc[cell_id]['Group']  # cell type of the current cell\n",
    "            # neigh_celltypes = np.array(celltypes_neighbors_df.loc[cell_id])[1:] # celltypes of neighbors excluding the first one (itself)\n",
    "            neigh_celltypes = np.array(celltypes_neighbors_df.loc[cell_id])\n",
    "            # neigh_batch_labels = np.array(batches_neighbors_df.loc[cell_id])[1:]    # batch labels of neighbors excluding the first one (itself)    \n",
    "            neigh_batch_labels = np.array(batches_neighbors_df.loc[cell_id])\n",
    "            neigh_celltypes_x = neigh_batch_labels[np.where(neigh_celltypes==cell_type)]    # batch labels of neighbors that have the same cell type as the current cell  \n",
    "            local_dist[b][cell_id] = len(neigh_celltypes_x[neigh_celltypes_x==b])   # number of same-type neighbors belong to the current batch b\n",
    "            global_dist[b][cell_id] = adata[(adata.obs.Batch==b) & (adata.obs.Group==cell_type)].shape[0]   # total cells of this type in batch b across the entire dataset\n",
    "\n",
    "    return local_dist, global_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad09e68a",
   "metadata": {},
   "source": [
    "### Distribution-based metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7cb1228f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl(p, q, epsilon=1e-10):\n",
    "    \"\"\"\n",
    "    Calculates KL divergence between two distributions\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    p and q : np.array\n",
    "        Two distributions\n",
    "    epsilon : scalar\n",
    "        To avoid infinity (i.e., division by zero)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    scalar\n",
    "        KL divergence score between two distributions\n",
    "    \"\"\"\n",
    "    \n",
    "    p = np.clip(p, a_min=epsilon, a_max=None)   # [0, 0] -> [eps, eps]; [0.7, 0] -> [0.7, eps]\n",
    "    q = np.clip(q, a_min=epsilon, a_max=None)\n",
    "\n",
    "    p /= p.sum()\n",
    "    q /= q.sum()\n",
    "\n",
    "    return np.sum(kl_div(p, q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1056f67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def js(p, q, epsilon=1e-10):\n",
    "    \"\"\"\n",
    "    Calculates JS distance between two distributions\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    p and q : np.array\n",
    "        Two distributions\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    scalar :\n",
    "        JS distance between two distributions\n",
    "    \"\"\"\n",
    "    \n",
    "    p = np.clip(p, a_min=epsilon, a_max=None)   # [0, 0] -> [eps, eps]; [0.7, 0] -> [0.7, eps]\n",
    "    q = np.clip(q, a_min=epsilon, a_max=None)\n",
    "\n",
    "    p /= p.sum()\n",
    "    q /= q.sum()\n",
    "\n",
    "    return jensenshannon(p, q, base=2.0)  # by default jensenshannon() uses log base e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7a3cf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tv(p, q, epsilon=1e-10):\n",
    "    \"\"\"\n",
    "    Calculates total variation distance between two distributions\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    p and q : np.array\n",
    "        Two distributions\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    scalar :\n",
    "        TV distance between two distributions\n",
    "    \"\"\"\n",
    "    \n",
    "    p = np.clip(p, a_min=epsilon, a_max=None)   # [0, 0] -> [eps, eps]; [0.7, 0] -> [0.7, eps]\n",
    "    q = np.clip(q, a_min=epsilon, a_max=None)\n",
    "\n",
    "    p /= p.sum()\n",
    "    q /= q.sum()\n",
    "\n",
    "    return 0.5 * np.sum(np.abs(p - q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f2ec6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hellinger(p, q, epsilon=1e-10):\n",
    "    \"\"\"\n",
    "    Calculates Hellinger distance between two distributions\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    p and q : np.array\n",
    "        Two distributions\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    scalar :\n",
    "        Hellinger distance between two distributions\n",
    "    \"\"\"\n",
    "    \n",
    "    p = np.clip(p, a_min=epsilon, a_max=None)   # [0, 0] -> [eps, eps]; [0.7, 0] -> [0.7, eps]\n",
    "    q = np.clip(q, a_min=epsilon, a_max=None)\n",
    "\n",
    "    p /= p.sum()\n",
    "    q /= q.sum()\n",
    "\n",
    "    return math.sqrt(sum([(math.sqrt(t[0])-math.sqrt(t[1]))*(math.sqrt(t[0])-math.sqrt(t[1]))\\\n",
    "                for t in zip(p,q)]))/math.sqrt(2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5480599c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi_sd(p, q, epsilon=1e-10):\n",
    "    \"\"\"\n",
    "    Calculates chi-square distance between two distributions\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    p and q : np.array\n",
    "        Two distributions\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    scalar :\n",
    "        Chi-square distance between two distributions\n",
    "    \"\"\"\n",
    "    \n",
    "    p = np.clip(p, a_min=epsilon, a_max=None)   # [0, 0] -> [eps, eps]; [0.7, 0] -> [0.7, eps]\n",
    "    q = np.clip(q, a_min=epsilon, a_max=None)\n",
    "\n",
    "    p /= p.sum()\n",
    "    q /= q.sum()\n",
    "\n",
    "    return 0.5 * np.sum(((p - q) ** 2) / (p + q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5170c25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wasserstein Distance\n",
    "\n",
    "# wasserstein_distance([0.2, 0.8], [0.8, 0.2]) does not treat those arrays as probability distributions.\n",
    "# It treats them as samples (locations).\n",
    "\n",
    "# As samples, both arrays contain the same points {0.2, 0.8}. The function sorts them first, so both become [0.2, 0.8].\n",
    "# Two identical sample sets ⇒ Wasserstein distance 0.0.\n",
    "\n",
    "# That’s why calling wasserstein_distance([0.2, 0.8], [0.8, 0.2]) returns 0.0.\n",
    "\n",
    "# To compare discrete distributions over known bins, pass the bin locations as values and the probabilities as weights:\n",
    "# wasserstein_distance(\n",
    "#    u_values=[0, 1], v_values=[0, 1],\n",
    "#    u_weights=[0.2, 0.8], v_weights=[0.8, 0.2]\n",
    "#) = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93955f51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.0), np.float64(0.6000000000000001))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wasserstein_distance([0.2, 0.8], [0.8, 0.2]), wasserstein_distance([0, 1], [0, 1], [0.2, 0.8], [0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da4a536a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wd(p, q, n_batches, epsilon=1e-10):\n",
    "    \"\"\"\n",
    "    Calculates Wasserstein distance between two distributions\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    p and q : np.array\n",
    "        Two distributions\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    scalar :\n",
    "        Wasserstein distance between two distributions\n",
    "    \"\"\"\n",
    "    \n",
    "    p = np.clip(p, a_min=epsilon, a_max=None)   # [0, 0] -> [eps, eps]; [0.7, 0] -> [0.7, eps]\n",
    "    q = np.clip(q, a_min=epsilon, a_max=None)\n",
    "    \n",
    "    p /= p.sum()\n",
    "    q /= q.sum()\n",
    "\n",
    "    x = np.arange(n_batches)\n",
    "\n",
    "    return wasserstein_distance(u_values=x, v_values=x, u_weights=p, v_weights=q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "810d8da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distr_based_metrics(scores, local_dist, global_dist, n_celltypes, n_batches):\n",
    "    \"\"\"\n",
    "    Calculates distribution-based metrics (i.e., KL, JS, TV, H, chiSD and WD).\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    scores : pd.DataFrame\n",
    "        Dataframe which will hold metric calculations (cell IDs are stored as the indices).\n",
    "    local_dist : pd.DataFrame\n",
    "        Local distribution for each cell\n",
    "    global_dist : pd.DataFrame\n",
    "        Global distribution for each cell\n",
    "    n_celltypes : scalar\n",
    "        Number of (unique) celltypes in the dataset\n",
    "    n_batches : scalar\n",
    "        Number of (unique) batches in the dataset\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    scores : pd.DataFrame\n",
    "        Metric calculation results\n",
    "    \"\"\"\n",
    "    \n",
    "    # identity matrix with shape n_batches x n_batches\n",
    "    I = np.eye(n_batches)\n",
    "    \n",
    "    scores [\"KL loc|glob\"] = 0.\n",
    "    scores [\"KL glob|loc\"] = 0.\n",
    "    scores [\"max KL loc|glob\"] = 0.\n",
    "    scores [\"max KL glob|loc\"] = 0.\n",
    "\n",
    "    scores [\"JS Dist\"] = 0.\n",
    "    scores [\"JS Div\"] = 0.\n",
    "    scores [\"max JS Dist\"] = 0.\n",
    "    scores [\"max JS Div\"] = 0.\n",
    "\n",
    "    scores [\"TV\"] = 0.\n",
    "    scores [\"max TV\"] = 0.\n",
    "\n",
    "    scores [\"H\"] = 0.\n",
    "    scores [\"max H\"] = 0.\n",
    "\n",
    "    scores [\"chiSD\"] = 0.\n",
    "    scores [\"max chiSD\"] = 0.\n",
    "\n",
    "    scores [\"WD\"] = 0.\n",
    "    scores [\"max WD\"] = 0.\n",
    "\n",
    "    for idx, cell_id in enumerate(scores.index):\n",
    "        loc  = np.array(local_dist.loc[cell_id])\n",
    "        glob = np.array(global_dist.loc[cell_id])\n",
    "\n",
    "        scores[\"KL loc|glob\"][cell_id] = kl(loc, glob)\n",
    "        scores[\"KL glob|loc\"][cell_id] = kl(glob, loc)\n",
    "\n",
    "        js_dist = js(loc, glob)\n",
    "        scores[\"JS Dist\"][cell_id] = js_dist\n",
    "        scores[\"JS Div\"][cell_id] = js_dist ** 2\n",
    "\n",
    "        scores[\"TV\"][cell_id] = tv(loc, glob)\n",
    "\n",
    "        scores[\"H\"][cell_id] = hellinger(loc, glob)\n",
    "\n",
    "        scores [\"chiSD\"][cell_id] = chi_sd(loc, glob)\n",
    "\n",
    "        scores [\"WD\"][cell_id] = wd(loc, glob, n_batches)\n",
    "\n",
    "        scores[\"max KL loc|glob\"][cell_id]  = scores[\"KL loc|glob\"][cell_id]\n",
    "        scores[\"max KL glob|loc\"][cell_id]  = scores[\"KL glob|loc\"][cell_id]\n",
    "        scores[\"max JS Dist\"][cell_id]      = scores[\"JS Dist\"][cell_id]\n",
    "        scores[\"max TV\"][cell_id]           = scores[\"TV\"][cell_id]\n",
    "        scores[\"max H\"][cell_id]            = scores[\"H\"][cell_id]\n",
    "        scores[\"max chiSD\"][cell_id]        = scores [\"chiSD\"][cell_id]\n",
    "        scores[\"max WD\"][cell_id]           = scores [\"WD\"][cell_id]\n",
    "\n",
    "        # get the max scores with this global distr (for each cell)\n",
    "        for i in I:\n",
    "            scores[\"max KL loc|glob\"][cell_id] = max(scores[\"max KL loc|glob\"][cell_id], kl(i, glob))\n",
    "            scores[\"max KL glob|loc\"][cell_id] = max(scores[\"max KL glob|loc\"][cell_id], kl(glob, i))\n",
    "\n",
    "            scores[\"max JS Dist\"][cell_id] = max(scores[\"max JS Dist\"][cell_id], js(i, glob))\n",
    "\n",
    "            scores[\"max TV\"][cell_id] = max(scores[\"max TV\"][cell_id], tv(i, glob))\n",
    "\n",
    "            scores[\"max H\"][cell_id] = max(scores[\"max H\"][cell_id], hellinger(i, glob))\n",
    "            \n",
    "            scores[\"max chiSD\"][cell_id] = max(scores[\"max chiSD\"][cell_id], chi_sd(i, glob))\n",
    "\n",
    "            scores[\"max WD\"][cell_id] = max(scores[\"max WD\"][cell_id], wd(i, glob, n_batches))\n",
    "\n",
    "        scores[\"max JS Div\"][cell_id] = scores[\"max JS Dist\"][cell_id] ** 2\n",
    "\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a319ce6",
   "metadata": {},
   "source": [
    "### Convential metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07313188",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conventional_metrics(adata, batch_key, group_key, embed=\"X_pca\"):\n",
    "    \"\"\"\n",
    "    Calculates conventional metrics (i.e., kBET, ASW batch, PCR, graph connectivity and isolated labels f1/asw).\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    adata : anndata object\n",
    "    batch_key : str\n",
    "        name of batch column in adata.obs\n",
    "    group_key : str\n",
    "        name of cell identity labels column in adata.obs\n",
    "    embed : str\n",
    "        embedding key in adata.obsm for embedding and feature input\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    kBET, ASW batch, PCR, graph_conn, iso_labels_f1/asw scores\n",
    "    \"\"\"\n",
    "\n",
    "    # kBET; 1: good batch mixing; 0: low batch mixing\n",
    "    kBET_scores = scib.me.kBET(\n",
    "            adata, batch_key=batch_key, label_key=group_key, type_=\"full\", embed=embed, return_df=True\n",
    "        )\n",
    "\n",
    "    # ASW batch\n",
    "    asw, sil_means, sil_df = scib.me.silhouette_batch(\n",
    "                adata, batch_key=batch_key, group_key=group_key, embed=embed, return_all=True)\n",
    "\n",
    "    asw_arr = np.array(sil_df[\"silhouette_score\"])\n",
    "\n",
    "    # PCR batch\n",
    "    pcr = scib.me.pcr(adata=adata, covariate=\"Batch\", embed=\"X_pca\")\n",
    "    \n",
    "    # graph connectivity\n",
    "    sc.pp.neighbors(adata, use_rep=\"X_pca\")\n",
    "    graph_conn = graph_connectivity_per_celltype(adata, label_key=group_key)\n",
    "\n",
    "    # isolated_labels_f1\n",
    "    iso_f1 = scib.me.isolated_labels_f1(adata=adata, label_key=group_key, batch_key=batch_key, embed=embed, return_all=True)\n",
    "\n",
    "    # number of cell types\n",
    "    n_celltypes = len(adata.obs[\"Group\"].unique())\n",
    "\n",
    "    # isoalated_labels_asw\n",
    "    # to calculate isolated labels asw we need at least 2 cell types\n",
    "    if n_celltypes < 2:\n",
    "        iso_asw = pd.Series([], dtype=object)\n",
    "    else:\n",
    "        iso_asw = isolated_labels_asw(adata=adata, label_key=group_key, batch_key=batch_key, embed=embed, return_all=True)\n",
    "    \n",
    "    return kBET_scores, asw_arr, pcr, graph_conn, iso_f1, iso_asw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e08272f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_metrics(scores):\n",
    "    \"\"\"\n",
    "    Normalizes distribution-based metrics so they can be between [0, 1].\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    scores : pd.DataFrame\n",
    "        Dataframe which will hold metric calculations (cell IDs are stored as the indices).\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    scores : pd.DataFrame\n",
    "        Metric calculation results\n",
    "    \"\"\"\n",
    "\n",
    "    scores[\"nKL loc|glob\"] = scores[\"KL loc|glob\"] / scores[\"max KL loc|glob\"]\n",
    "    scores[\"nKL glob|loc\"] = scores[\"KL glob|loc\"] / scores[\"max KL glob|loc\"]\n",
    "    scores[\"nJS Dist\"] = scores[\"JS Dist\"] / scores[\"max JS Dist\"]\n",
    "    scores[\"nJS Div\"] = scores[\"JS Div\"] / scores[\"max JS Div\"]\n",
    "    scores[\"nTV\"] = scores[\"TV\"] / scores[\"max TV\"]\n",
    "    scores[\"nH\"] = scores[\"H\"] / scores[\"max H\"]\n",
    "    scores[\"nChiSD\"] = scores[\"chiSD\"] / scores[\"max chiSD\"]\n",
    "    scores[\"nWD\"] = scores[\"WD\"] / scores[\"max WD\"]\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ffc5fe08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_metrics(scores):\n",
    "    \"\"\"\n",
    "    Calculates weighted metrics.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    scores : pd.DataFrame\n",
    "        Dataframe which will hold metric calculations (cell IDs are stored as the indices).\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    scores : pd.DataFrame\n",
    "        Metric calculation results\n",
    "    \"\"\"\n",
    "\n",
    "    scores[\"wKL loc|glob\"] = scores[\"weight\"] * scores[\"KL loc|glob\"]\n",
    "    scores[\"wnKL loc|glob\"] = scores[\"weight\"] * scores[\"nKL loc|glob\"]\n",
    "\n",
    "    scores[\"wKL glob|loc\"] = scores[\"weight\"] * scores[\"KL glob|loc\"]\n",
    "    scores[\"wnKL glob|loc\"] = scores[\"weight\"] * scores[\"nKL glob|loc\"]\n",
    "    \n",
    "    scores[\"wJS Dist\"] = scores[\"weight\"] * scores[\"JS Dist\"]\n",
    "    scores[\"wnJS Dist\"] = scores[\"weight\"] * scores[\"nJS Dist\"]\n",
    "\n",
    "    scores[\"wJS Div\"] = scores[\"weight\"] * scores[\"JS Div\"]\n",
    "    scores[\"wnJS Div\"] = scores[\"weight\"] * scores[\"nJS Div\"]\n",
    "\n",
    "    scores[\"wTV\"] = scores[\"weight\"] * scores[\"TV\"]\n",
    "    scores[\"wnTV\"] = scores[\"weight\"] * scores[\"nTV\"]\n",
    "\n",
    "    scores[\"wH\"] = scores[\"weight\"] * scores[\"H\"]\n",
    "    scores[\"wnH\"] = scores[\"weight\"] * scores[\"nH\"]\n",
    "\n",
    "    scores[\"w_nILISI\"] = scores[\"weight\"] * scores[\"n_iLISI\"]\n",
    "    \n",
    "    scores[\"wChiSD\"] = scores[\"weight\"] * scores[\"chiSD\"]\n",
    "    scores[\"wnChiSD\"] = scores[\"weight\"] * scores[\"nChiSD\"]\n",
    "\n",
    "    scores[\"wWD\"] = scores[\"weight\"] * scores[\"WD\"]\n",
    "    scores[\"wnWD\"] = scores[\"weight\"] * scores[\"nWD\"]\n",
    "\n",
    "    scores[\"wASW\"] = scores[\"weight\"] * scores[\"1-ASW\"]\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f585dc",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6be016d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['circular_n_genes_2000',\n",
       " 'elliptical_distant_n_genes_2000',\n",
       " 'elliptical_n_genes_2000',\n",
       " 'intersecting_diagonal_n_genes_2000',\n",
       " 'intersecting_diagonal_more_points_intersect_n_genes_2000']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d22ad75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "ct_list = []\n",
    "b_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "33663a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reducing data...\n",
      "HVG\n",
      "Using 2000 HVGs from full intersect set\n",
      "Using 0 HVGs from n_batch-1 set\n",
      "Using 2000 HVGs\n",
      "Computed 2000 highly variable genes\n",
      "PCA\n",
      "Nearest Neigbours\n",
      "UMAP\n",
      "Calculating mean distances to same type cells...\n",
      "Building distributions...\n",
      "<class 'str'> Batch1\n",
      "<class 'str'> Batch0\n",
      "<class 'str'> Batch1\n",
      "<class 'str'> Batch0\n",
      "<class 'str'> Batch1\n",
      "<class 'str'> Batch0\n",
      "Calculating metrics k=90...\n",
      "0 labels consist of a single batch or is too small. Skip.\n",
      "mean silhouette per group:        silhouette_score\n",
      "group                  \n",
      "Type1          0.597558\n",
      "isolated labels: []\n",
      "Type1\n",
      "Type1\n",
      "Calculating metrics k=60...\n",
      "0 labels consist of a single batch or is too small. Skip.\n",
      "mean silhouette per group:        silhouette_score\n",
      "group                  \n",
      "Type1          0.597558\n",
      "isolated labels: []\n",
      "Type1\n",
      "Type1\n",
      "Calculating metrics k=30...\n",
      "0 labels consist of a single batch or is too small. Skip.\n",
      "mean silhouette per group:        silhouette_score\n",
      "group                  \n",
      "Type1          0.597558\n",
      "isolated labels: []\n",
      "Type1\n",
      "Type1\n",
      "Reducing data...\n",
      "HVG\n",
      "Using 1729 HVGs from full intersect set\n",
      "Using 271 HVGs from n_batch-1 set\n",
      "Using 2000 HVGs\n",
      "Computed 2000 highly variable genes\n",
      "PCA\n",
      "Nearest Neigbours\n",
      "UMAP\n",
      "Calculating mean distances to same type cells...\n",
      "Building distributions...\n",
      "<class 'str'> Batch1\n",
      "<class 'str'> Batch0\n",
      "<class 'str'> Batch1\n",
      "<class 'str'> Batch0\n",
      "<class 'str'> Batch1\n",
      "<class 'str'> Batch0\n",
      "Calculating metrics k=90...\n",
      "0 labels consist of a single batch or is too small. Skip.\n",
      "mean silhouette per group:        silhouette_score\n",
      "group                  \n",
      "Type1          0.262384\n",
      "isolated labels: []\n",
      "Type1\n",
      "Type1\n",
      "Calculating metrics k=60...\n",
      "0 labels consist of a single batch or is too small. Skip.\n",
      "mean silhouette per group:        silhouette_score\n",
      "group                  \n",
      "Type1          0.262384\n",
      "isolated labels: []\n",
      "Type1\n",
      "Type1\n",
      "Calculating metrics k=30...\n",
      "0 labels consist of a single batch or is too small. Skip.\n",
      "mean silhouette per group:        silhouette_score\n",
      "group                  \n",
      "Type1          0.262384\n",
      "isolated labels: []\n",
      "Type1\n",
      "Type1\n",
      "Reducing data...\n",
      "HVG\n",
      "Using 2000 HVGs from full intersect set\n",
      "Using 0 HVGs from n_batch-1 set\n",
      "Using 2000 HVGs\n",
      "Computed 2000 highly variable genes\n",
      "PCA\n",
      "Nearest Neigbours\n",
      "UMAP\n",
      "Calculating mean distances to same type cells...\n",
      "Building distributions...\n",
      "<class 'str'> Batch1\n",
      "<class 'str'> Batch0\n",
      "<class 'str'> Batch1\n",
      "<class 'str'> Batch0\n",
      "<class 'str'> Batch1\n",
      "<class 'str'> Batch0\n",
      "Calculating metrics k=90...\n",
      "0 labels consist of a single batch or is too small. Skip.\n",
      "mean silhouette per group:        silhouette_score\n",
      "group                  \n",
      "Type1          0.786486\n",
      "isolated labels: []\n",
      "Type1\n",
      "Type1\n",
      "Calculating metrics k=60...\n",
      "0 labels consist of a single batch or is too small. Skip.\n",
      "mean silhouette per group:        silhouette_score\n",
      "group                  \n",
      "Type1          0.786486\n",
      "isolated labels: []\n",
      "Type1\n",
      "Type1\n",
      "Calculating metrics k=30...\n",
      "0 labels consist of a single batch or is too small. Skip.\n",
      "mean silhouette per group:        silhouette_score\n",
      "group                  \n",
      "Type1          0.786486\n",
      "isolated labels: []\n",
      "Type1\n",
      "Type1\n",
      "Reducing data...\n",
      "HVG\n",
      "Using 2000 HVGs from full intersect set\n",
      "Using 0 HVGs from n_batch-1 set\n",
      "Using 2000 HVGs\n",
      "Computed 2000 highly variable genes\n",
      "PCA\n",
      "Nearest Neigbours\n",
      "UMAP\n",
      "Calculating mean distances to same type cells...\n",
      "Building distributions...\n",
      "<class 'str'> Batch0\n",
      "<class 'str'> Batch1\n",
      "<class 'str'> Batch0\n",
      "<class 'str'> Batch1\n",
      "<class 'str'> Batch0\n",
      "<class 'str'> Batch1\n",
      "Calculating metrics k=90...\n",
      "0 labels consist of a single batch or is too small. Skip.\n",
      "mean silhouette per group:        silhouette_score\n",
      "group                  \n",
      "Type1          0.561416\n",
      "isolated labels: []\n",
      "Type1\n",
      "Type1\n",
      "Calculating metrics k=60...\n",
      "0 labels consist of a single batch or is too small. Skip.\n",
      "mean silhouette per group:        silhouette_score\n",
      "group                  \n",
      "Type1          0.561416\n",
      "isolated labels: []\n",
      "Type1\n",
      "Type1\n",
      "Calculating metrics k=30...\n",
      "0 labels consist of a single batch or is too small. Skip.\n",
      "mean silhouette per group:        silhouette_score\n",
      "group                  \n",
      "Type1          0.561416\n",
      "isolated labels: []\n",
      "Type1\n",
      "Type1\n",
      "Reducing data...\n",
      "HVG\n",
      "Using 2000 HVGs from full intersect set\n",
      "Using 0 HVGs from n_batch-1 set\n",
      "Using 2000 HVGs\n",
      "Computed 2000 highly variable genes\n",
      "PCA\n",
      "Nearest Neigbours\n",
      "UMAP\n",
      "Calculating mean distances to same type cells...\n",
      "Building distributions...\n",
      "<class 'str'> Batch0\n",
      "<class 'str'> Batch1\n",
      "<class 'str'> Batch0\n",
      "<class 'str'> Batch1\n",
      "<class 'str'> Batch0\n",
      "<class 'str'> Batch1\n",
      "Calculating metrics k=90...\n",
      "0 labels consist of a single batch or is too small. Skip.\n",
      "mean silhouette per group:        silhouette_score\n",
      "group                  \n",
      "Type1          0.676188\n",
      "isolated labels: []\n",
      "Type1\n",
      "Type1\n",
      "Calculating metrics k=60...\n",
      "0 labels consist of a single batch or is too small. Skip.\n",
      "mean silhouette per group:        silhouette_score\n",
      "group                  \n",
      "Type1          0.676188\n",
      "isolated labels: []\n",
      "Type1\n",
      "Type1\n",
      "Calculating metrics k=30...\n",
      "0 labels consist of a single batch or is too small. Skip.\n",
      "mean silhouette per group:        silhouette_score\n",
      "group                  \n",
      "Type1          0.676188\n",
      "isolated labels: []\n",
      "Type1\n",
      "Type1\n"
     ]
    }
   ],
   "source": [
    "for scenario in scenarios:\n",
    "\n",
    "    sc_dir = f\"{results_dir}/{scenario}\"\n",
    "    os.makedirs(sc_dir, exist_ok=True)\n",
    "\n",
    "    adata = sc.read_h5ad(f\"sil_{scenario}.h5ad\")\n",
    "\n",
    "    # rename\n",
    "    adata.obs.rename(columns={\n",
    "        \"cell_type\": \"Group\",\n",
    "        \"batch\": \"Batch\"\n",
    "    }, inplace=True)\n",
    "\n",
    "    print(\"Reducing data...\")\n",
    "    scib.preprocessing.reduce_data(adata, batch_key=\"Batch\", umap=True)\n",
    "\n",
    "    # keep only HVGs\n",
    "    adata = adata[:, adata.var[\"highly_variable\"]].copy()\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Calculating mean distances to same type cells...\")\n",
    "\n",
    "    pca_coords = adata.obsm[\"X_pca\"]\n",
    "\n",
    "    cell_types = adata.obs[\"Group\"]\n",
    "    batches = adata.obs[\"Batch\"]\n",
    "\n",
    "    adata.obs['normalized_mean_dist_to_same_type'] = mean_dists_to_same_type_cells(pca_coords, cell_types)\n",
    "\n",
    "    emb = \"pca\"\n",
    "    if emb == \"pca\":\n",
    "        emb_coords = adata.obsm[\"X_pca\"][:, :2]\n",
    "    # umap\n",
    "    else:\n",
    "        emb_coords = adata.obsm[\"X_umap\"]\n",
    "\n",
    "    out_file = f\"{sc_dir}/{scenario}_{emb}_and_distrs.png\"\n",
    "\n",
    "    print(\"Building distributions...\")\n",
    "\n",
    "    int_df = pd.DataFrame(pca_coords)\n",
    "\n",
    "    k = 90  # number of neighbors for each cell\n",
    "\n",
    "    idx, dists = knn(int_df, k=k)\n",
    "    dknn_df = pd.DataFrame(idx, index=int_df.index)\n",
    "    dists_df = pd.DataFrame(dists, index=int_df.index)\n",
    "\n",
    "    dknn_df_k60 = dknn_df.iloc[:, :60]\n",
    "    dknn_df_k30 = dknn_df.iloc[:, :30]\n",
    "\n",
    "    celltypes_df = pd.DataFrame(adata.obs.Group)\n",
    "    batches_df = pd.DataFrame(adata.obs.Batch)\n",
    "\n",
    "    local_dist, global_dist = build_distributions(adata,     dknn_df, celltypes_df, batches_df)\n",
    "    local_dist_k60, _       = build_distributions(adata, dknn_df_k60, celltypes_df, batches_df)\n",
    "    local_dist_k30, _       = build_distributions(adata, dknn_df_k30, celltypes_df, batches_df)\n",
    "\n",
    "\n",
    "    # out_file = f\"{sc_dir}/{scenario}_emb_and_global\"\n",
    "\n",
    "    # plot_emb_and_global_pub(\n",
    "    #    scenario=scenario,\n",
    "    #    coords=emb_coords,\n",
    "    #    cell_types=cell_types,\n",
    "    #    batches=batches,\n",
    "    #    local_dist=None, global_dist=None,  # ignored\n",
    "    #    out_file=out_file,\n",
    "    #    emb=emb,\n",
    "    #    export_png=True, png_dpi=600,\n",
    "    #    sort_by_total=False, ascending=False,  # optional\n",
    "    # )\n",
    "\n",
    "    if scenario == \"elliptical_n_genes_2000\" or scenario == \"intersecting_diagonal_more_points_intersect_n_genes_2000\":\n",
    "        embeddings.append(\n",
    "            (scenario, emb_coords)\n",
    "        )\n",
    "        ct_list.append(cell_types)\n",
    "        b_list.append(batches)\n",
    "\n",
    "    # continue\n",
    "\n",
    "    # plot_emb_and_distrs(scenario=scenario, coords=emb_coords, cell_types=cell_types, batches=batches,\n",
    "    #                    local_dist=local_dist.copy(), global_dist=global_dist.copy(), out_file=out_file,\n",
    "    #                    emb=emb, local_dist_k60=local_dist_k60.copy(), local_dist_k30=local_dist_k30.copy())\n",
    "\n",
    "    n_celltypes = len(celltypes_df[\"Group\"].unique())\n",
    "    n_batches = len(batches_df[\"Batch\"].unique())\n",
    "\n",
    "    for k in [90, 60, 30]:\n",
    "        print(f\"Calculating metrics k={k}...\")\n",
    "        scores = pd.DataFrame(0., columns=[], index=global_dist.index)\n",
    "        scores[\"Cell type\"] = celltypes_df\n",
    "        scores[\"Batch\"] = batches_df\n",
    "        scores[\"weight\"] = adata.obs[\"normalized_mean_dist_to_same_type\"]\n",
    "\n",
    "        if k == 60:\n",
    "            local_dist = local_dist_k60\n",
    "        if k == 30:\n",
    "            local_dist = local_dist_k30\n",
    "\n",
    "        scores = distr_based_metrics(scores, local_dist.copy(), global_dist.copy(), n_celltypes, n_batches)\n",
    "\n",
    "        # LISI\n",
    "        %R library(lisi)\n",
    "        %R -i int_df,batches_df,celltypes_df,k\n",
    "        %R cLISI=lisi::compute_lisi(int_df, data.frame(celltypes_df), colnames(celltypes_df), perplexity=k/3)\n",
    "        %R iLISI=lisi::compute_lisi(int_df, data.frame(batches_df), colnames(batches_df), perplexity=k/3)\n",
    "        %R -o iLISI,cLISI\n",
    "\n",
    "        scores[\"iLISI\"] = np.array(iLISI[\"Batch\"])\n",
    "        scores[\"cLISI\"] = np.array(cLISI[\"Group\"])\n",
    "\n",
    "        kBET_scores, asw_arr, pcr, graph_conn, iso_f1, iso_asw = conventional_metrics(adata, batch_key=\"Batch\", group_key=\"Group\")\n",
    "\n",
    "        if len(asw_arr) == len(scores.index):\n",
    "            scores[\"ASW\"] = asw_arr\n",
    "        else:\n",
    "            scores[\"ASW\"] = np.nan\n",
    "            \n",
    "        scores[\"PCR\"] = pcr\n",
    "\n",
    "        scores[\"iLISI\"] = scores[\"iLISI\"].clip(upper=n_batches)\n",
    "\n",
    "        # Normalize iLISI so 0 can be interpreted as good batch mixing and 1 as bad batch mixing\n",
    "        scores[\"n_iLISI\"] = (n_batches - scores[\"iLISI\"]) / (n_batches - 1)\n",
    "\n",
    "        # Initially, ASW = 1 means different batches are mixing well. After inversion, ASW = 0 means batches are not mixing well.\n",
    "        scores[\"1-ASW\"] = 1 - scores[\"ASW\"]\n",
    "\n",
    "        # normalize distribution-based metrics\n",
    "        scores = normalize_metrics(scores)\n",
    "\n",
    "        # weight scores\n",
    "        scores = weighted_metrics(scores)\n",
    "\n",
    "        # detailed scores\n",
    "        detailed_scores = pd.DataFrame(columns=scores.columns, index=sorted(adata.obs.Group.unique()))\n",
    "        detailed_scores = detailed_scores.drop(columns=[\"Cell type\", \"Batch\"])\n",
    "\n",
    "        for bt in adata.obs.Batch.unique():\n",
    "            detailed_scores[f\"#{bt}\"] = 0.\n",
    "\n",
    "        for ct in adata.obs.Group.unique():\n",
    "            print(ct)\n",
    "            detailed_scores.loc[ct] = scores.loc[celltypes_df[celltypes_df.Group==ct].index].drop(columns=[\"Cell type\", \"Batch\"]).mean()\n",
    "                \n",
    "            for bt in adata.obs.Batch.unique():\n",
    "                detailed_scores[f\"#{bt}\"][ct] = scores[(scores[\"Batch\"] == bt) & (scores[\"Cell type\"] == ct)].shape[0]\n",
    "\n",
    "        detailed_scores[\"kBET\"] = np.nan\n",
    "        for i in range(len(kBET_scores[\"cluster\"])):\n",
    "            print(kBET_scores[\"cluster\"][i])\n",
    "            detailed_scores[\"kBET\"][kBET_scores[\"cluster\"][i]] = kBET_scores[\"kBET\"][i]\n",
    "\n",
    "        # kBET = 0 means different batches are mixing well\n",
    "        detailed_scores[\"wkBET\"] = detailed_scores[\"kBET\"] * detailed_scores[\"weight\"]\n",
    "\n",
    "        # add graph_conn col\n",
    "        detailed_scores[\"graph_conn\"] = detailed_scores.index.map(graph_conn)\n",
    "\n",
    "        detailed_scores[\"1-graph_conn\"] = 1 - detailed_scores[\"graph_conn\"]\n",
    "\n",
    "        detailed_scores[\"wGraph_conn\"] = detailed_scores[\"1-graph_conn\"] * detailed_scores[\"weight\"]\n",
    "\n",
    "        if iso_f1.empty:\n",
    "            detailed_scores[\"isolated_labels_f1\"] = np.nan\n",
    "        else:\n",
    "            detailed_scores[\"isolated_labels_f1\"] = iso_f1\n",
    "\n",
    "        if iso_asw.empty:\n",
    "            detailed_scores[\"isolated_labels_asw\"] = np.nan\n",
    "        else:\n",
    "            detailed_scores[\"isolated_labels_asw\"] = iso_asw\n",
    "\n",
    "        # reorder columns\n",
    "        assert sorted(detailed_scores.columns) == sorted(col_order)\n",
    "        detailed_scores = detailed_scores[col_order]\n",
    "\n",
    "        round(detailed_scores,5).to_excel(f\"{sc_dir}/{scenario}_n_genes_2000_k_{k}_scores_celltypes_all_batches.xlsx\")\n",
    "        round(scores,5).to_excel(f\"{sc_dir}/{scenario}_n_genes_2000_k_{k}_scores_all_batches.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e6b098b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elliptical_n_genes_2000\n",
      "intersecting_diagonal_more_points_intersect_n_genes_2000\n"
     ]
    }
   ],
   "source": [
    "for s, arr in embeddings:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "98b7e732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../results/2025-07-11/out/geom_n_genes_2000_embs_and_global'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_file = f\"{results_dir}/geom_n_genes_2000_embs_and_global\"\n",
    "\n",
    "out_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "90ecdf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_emb_and_global_pub_geom(\n",
    "    embeddings=embeddings,                 # list of (emb_name, coords_nx2); expects 5 items\n",
    "    cell_types=ct_list,                 # pd.Series, index aligned to coords rows\n",
    "    batches=b_list,                    # pd.Series, index aligned to coords rows\n",
    "    global_dist=global_dist,                # pd.DataFrame (optional ordering), columns=batches\n",
    "    out_file=out_file,\n",
    "    # layout=(1, 3),              # (rows, cols); expects rows*cols>=6\n",
    "    export_png=True, png_dpi=600,\n",
    "    sort_by_total=False, ascending=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d36ebabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of the notebook\n"
     ]
    }
   ],
   "source": [
    "print(\"End of the notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918017b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metric-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
